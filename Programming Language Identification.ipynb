{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Language Identification\n",
    "Uses a character-level recurrent convolutional model to identify the programming languages of lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "PYTHON = 0\n",
    "JAVA = 1\n",
    "C = 2\n",
    "CPP = 3\n",
    "\n",
    "# Languages to use for the identification task.\n",
    "# Note that Python vs. C++ is a fairly easy task.\n",
    "LANGS_TO_USE = [PYTHON, CPP]\n",
    "\n",
    "# Repos containing large amounts of code for each language\n",
    "CODE_DIRS = {\n",
    "    PYTHON: \"./data/django\",\n",
    "    JAVA: \"./data/ohc\",\n",
    "    C: \"./data/freebsd\",\n",
    "    CPP: \"./data/caffe\"\n",
    "}\n",
    "\n",
    "# Filename extensions for each language\n",
    "EXTS = {\n",
    "    PYTHON: {\"py\"},\n",
    "    JAVA: {\"java\"},\n",
    "    C: {\"c\", \"h\"},\n",
    "    CPP: {\"cpp\", \"cc\"}\n",
    "}\n",
    "\n",
    "# Maximum number of characters for each language\n",
    "N_CHARS = {\n",
    "    PYTHON: 1000000,\n",
    "    JAVA: 1000000,\n",
    "    C: 1000000,\n",
    "    CPP: 1000000\n",
    "}\n",
    "\n",
    "# Full names of languages; used for printing\n",
    "LANG_NAMES = {\n",
    "    PYTHON: \"Python\",\n",
    "    JAVA: \"Java\",\n",
    "    C: \"C\",\n",
    "    CPP: \"C++\"\n",
    "}\n",
    "\n",
    "MAX_LINES = 20000  # Max lines across all languages\n",
    "LENGTH_PERCENTILE = 95  # Percentile of the line lengths to use as the max line length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAllCodeByExt(path, extensions, maxChars=float(\"inf\")):\n",
    "    \"\"\"Given a set of extensions, returns a string consisting of\n",
    "    at most maxChars characters from the concatenation of all files\n",
    "    under the given path with any of the given extensions.\"\"\"\n",
    "    result = \"\"\n",
    "    for name in os.listdir(path):\n",
    "        newPath = os.path.join(path, name)\n",
    "        if os.path.isfile(newPath):\n",
    "            _, ext = os.path.splitext(newPath)\n",
    "            if ext[1:] in extensions:\n",
    "                with open(newPath) as f:\n",
    "                    result += f.read()\n",
    "        else:\n",
    "            result += getAllCodeByExt(newPath, extensions)\n",
    "        if len(result) > maxChars:\n",
    "            result = result[:maxChars]\n",
    "            return result\n",
    "    return result\n",
    "\n",
    "# Code preprocessors\n",
    "\n",
    "def preprocessPythonCode(code):\n",
    "    code = re.sub(r\"\\s*\\n\", \"\\n\", code)\n",
    "    code = re.sub(r\"\\\"\\\"\\\"(.+?)\\\"\\\"\\\"\", \"<comment>\", code, flags=re.DOTALL)\n",
    "    code = re.sub(r\"(\\#(.+?)\\n)+\", \"<comment>\\n\", code)\n",
    "    code = re.sub(r\"\\\"(.+?)\\\"|\\'(.+?)\\'\", \"<string>\", code)\n",
    "    code = re.sub(r\"\\d\", \"#\", code)\n",
    "    return code\n",
    "\n",
    "def preprocessCLikeCode(code):\n",
    "    code = re.sub(r\"\\s*\\n\", \"\\n\", code)\n",
    "    code = re.sub(r\"/\\*(.+?)\\*/\", \"<comment>\", code, flags=re.DOTALL)\n",
    "    code = re.sub(r\"//(.+?)\\n\", \"<comment>\\n\", code)\n",
    "    code = re.sub(r\"\\#(.+?)\\n\", \"<macro>\\n\", code)\n",
    "    code = re.sub(r\"\\\"(.+?)\\\"\", \"<string>\", code)\n",
    "    code = re.sub(r\"\\'(.+?)\\'\", \"<char>\", code)\n",
    "    code = re.sub(r\"\\d\", \"#\", code)\n",
    "    return code\n",
    "\n",
    "preprocessors = {\n",
    "    PYTHON: preprocessPythonCode,\n",
    "    JAVA: preprocessCLikeCode,\n",
    "    C: preprocessCLikeCode,\n",
    "    CPP: preprocessCLikeCode\n",
    "}\n",
    "\n",
    "# Code retrieval\n",
    "\n",
    "def getCode(language, preprocess=False):\n",
    "    \"\"\"Return all code for the specified language, optionally preprocessed.\"\"\"\n",
    "    code = getAllCodeByExt(CODE_DIRS[language], EXTS[language], N_CHARS[language])\n",
    "    return preprocessors[language](code) if preprocess else code\n",
    "\n",
    "# Data processing\n",
    "\n",
    "def lineToOneHot(line, indexing):\n",
    "    \"\"\"Given a line of text and an indexing from characters to indices,\n",
    "    returns a sequence of one-hot vectors encoding the line.\"\"\"\n",
    "    return np.array([[int(i == indexing[c]) for i in range(nChars)] for c in line])\n",
    "\n",
    "def oneHotToLine(oneHot, invIndexing):\n",
    "    \"\"\"Given a one-hot vector sequence and an inverse indexing from indices to\n",
    "    characters, returns the line of text encoded by the sequence.\"\"\"\n",
    "    return \"\".join([invIndexing[val] for val in oneHot.argmax(1)])\n",
    "\n",
    "def cropToLength(seq, length):\n",
    "    \"\"\"Crops seq to the specified length or pads it with zeros to the\n",
    "    specified length. No change if seq.shape[0] == length.\"\"\"\n",
    "    if seq.shape[0] == length:\n",
    "        return seq\n",
    "    elif seq.shape[0] > length:\n",
    "        return seq[:length, :]\n",
    "    else:\n",
    "        neededPad = length - seq.shape[0]\n",
    "        return np.pad(seq, [(0, neededPad), (0, 0)], \"constant\")\n",
    "\n",
    "# Model utilities\n",
    "    \n",
    "def queryModel(model, line, indexing):\n",
    "    \"\"\"Given a Keras model, a line, and a char-index indexing, determine the language\n",
    "    scores for the line.\"\"\"\n",
    "    seq = cropToLength(lineToOneHot(line, indexing), targetLength)\n",
    "    output = model.predict(np.array([seq]))[0]\n",
    "    scores = [(LANG_NAMES[lang], output[idx]) for idx, lang in enumerate(LANGS_TO_USE)]\n",
    "    sortedScores = sorted(scores, key=lambda (lang, score): -score)\n",
    "    return sortedScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 185 chars.\n",
      "Using 20000 lines of Python.\n",
      "Using 20000 lines of C++.\n",
      "Total: 40000 lines from 2 codebases.\n",
      "Using 95th percentile line length = 77\n"
     ]
    }
   ],
   "source": [
    "# Set up and analyze codebases\n",
    "\n",
    "# Set preprocess=True in getCode to preprocess the code\n",
    "codeBases = {lang:getCode(lang) for lang in LANGS_TO_USE}\n",
    "nLangs = len(LANGS_TO_USE)\n",
    "\n",
    "allChars = reduce(lambda x, y: set(x) | set(y), codeBases.values())\n",
    "nChars = len(allChars)\n",
    "print \"Using %d chars.\" % nChars\n",
    "\n",
    "indexing = {c:idx for idx, c in enumerate(allChars)}\n",
    "invIndexing = {idx:c for c, idx in indexing.iteritems()}\n",
    "\n",
    "# Construct data arrays\n",
    "\n",
    "XList, yList = [], []\n",
    "for idx, lang in enumerate(LANGS_TO_USE):\n",
    "    labelVec = np.array([int(i == idx) for i in range(nLangs)])\n",
    "    text = codeBases[lang]\n",
    "    nLines = 0\n",
    "    for line in text.split(\"\\n\"):\n",
    "        lineVec = lineToOneHot(line, indexing)\n",
    "        if lineVec.size > 0:\n",
    "            XList.append(lineVec)\n",
    "            yList.append(labelVec)\n",
    "            nLines += 1\n",
    "        if nLines == MAX_LINES:\n",
    "            break\n",
    "    print \"Using %d lines of %s.\" % (nLines, LANG_NAMES[lang])\n",
    "    \n",
    "print \"Total: %d lines from %d codebases.\" % (len(XList), nLangs)\n",
    "\n",
    "lengths = [vec.shape[0] for vec in XList]\n",
    "targetLength = int(np.percentile(lengths, LENGTH_PERCENTILE))\n",
    "print \"Using %dth percentile line length = %d\" % (LENGTH_PERCENTILE, targetLength)\n",
    "XList = [cropToLength(vec, targetLength) for vec in XList]\n",
    "\n",
    "X = np.array(XList)\n",
    "y = np.array(yList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/3\n",
      "36000/36000 [==============================] - 80s - loss: 0.0723 - acc: 0.9730 - val_loss: 0.3112 - val_acc: 0.9557\n",
      "Epoch 2/3\n",
      "36000/36000 [==============================] - 82s - loss: 0.0288 - acc: 0.9913 - val_loss: 0.0831 - val_acc: 0.9815\n",
      "Epoch 3/3\n",
      "36000/36000 [==============================] - 79s - loss: 0.0213 - acc: 0.9940 - val_loss: 0.1354 - val_acc: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231ad7950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model setup, training, and eval\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution1D, MaxPooling1D, LSTM, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "model = Sequential([\n",
    "        # This layer should extract language-specific character\n",
    "        # sequences, like \"class\" or \"import\"\n",
    "        Convolution1D(64, 7, input_shape=(targetLength, nChars), activation=\"relu\"),\n",
    "        MaxPooling1D(pool_length=7),\n",
    "        Dropout(0.5),\n",
    "        # This LSTM doesn't need to be bidirectional because we don't expect \n",
    "        # character ordering to have any semantic value\n",
    "        LSTM(256),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(nLangs, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(X, y, nb_epoch=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python                                                                   Python with 99.94 confidence\n",
      "\"\"\"                                                                                     Python with 99.91 confidence\n",
      "classify.py is an out-of-the-box image classifer callable from the command line.        Python with 99.98 confidence\n",
      "\n",
      "By default it configures and runs the Caffe reference ImageNet model.                   Python with 99.82 confidence\n",
      "\"\"\"                                                                                     Python with 99.91 confidence\n",
      "import numpy as np                                                                      Python with 99.97 confidence\n",
      "import os                                                                               Python with 99.99 confidence\n",
      "import sys                                                                              Python with 99.99 confidence\n",
      "import argparse                                                                         Python with 100.00 confidence\n",
      "import glob                                                                             Python with 99.73 confidence\n",
      "import time                                                                             Python with 99.97 confidence\n",
      "\n",
      "import caffe                                                                            C++ with 63.60 confidence\n",
      "\n",
      "\n",
      "def main(argv):                                                                         Python with 100.00 confidence\n",
      "    pycaffe_dir = os.path.dirname(__file__)                                             Python with 98.17 confidence\n",
      "\n",
      "    parser = argparse.ArgumentParser()                                                  Python with 100.00 confidence\n",
      "    # Required arguments: input and output files.                                       Python with 100.00 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"input_file\",                                                                   C++ with 74.54 confidence\n",
      "        help=\"Input image, directory, or npy.\"                                          Python with 99.99 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"output_file\",                                                                  C++ with 82.46 confidence\n",
      "        help=\"Output npy filename.\"                                                     Python with 100.00 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    # Optional arguments.                                                               Python with 100.00 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--model_def\",                                                                  Python with 80.22 confidence\n",
      "        default=os.path.join(pycaffe_dir,                                               Python with 99.98 confidence\n",
      "                \"../models/bvlc_reference_caffenet/deploy.prototxt\"),                   Python with 99.93 confidence\n",
      "        help=\"Model definition file.\"                                                   Python with 100.00 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--pretrained_model\",                                                           Python with 99.73 confidence\n",
      "        default=os.path.join(pycaffe_dir,                                               Python with 99.98 confidence\n",
      "                \"../models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel\"),Python with 99.81 confidence\n",
      "        help=\"Trained model weights file.\"                                              Python with 100.00 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--gpu\",                                                                        C++ with 63.02 confidence\n",
      "        action='store_true',                                                            Python with 100.00 confidence\n",
      "        help=\"Switch for gpu computation.\"                                              Python with 100.00 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--center_only\",                                                                Python with 63.07 confidence\n",
      "        action='store_true',                                                            Python with 100.00 confidence\n",
      "        help=\"Switch for prediction from center crop alone instead of \" +               Python with 100.00 confidence\n",
      "             \"averaging predictions across crops (default).\"                            Python with 99.97 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--images_dim\",                                                                 Python with 81.77 confidence\n",
      "        default='256,256',                                                              Python with 100.00 confidence\n",
      "        help=\"Canonical 'height,width' dimensions of input images.\"                     Python with 100.00 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--mean_file\",                                                                  C++ with 50.33 confidence\n",
      "        default=os.path.join(pycaffe_dir,                                               Python with 99.98 confidence\n",
      "                             'caffe/imagenet/ilsvrc_2012_mean.npy'),                    Python with 99.72 confidence\n",
      "        help=\"Data set image mean of [Channels x Height x Width] dimensions \" +         Python with 99.97 confidence\n",
      "             \"(numpy array). Set to '' for no mean subtraction.\"                        Python with 99.98 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--input_scale\",                                                                Python with 50.92 confidence\n",
      "        type=float,                                                                     Python with 96.24 confidence\n",
      "        help=\"Multiply input features by this scale to finish preprocessing.\"           Python with 99.95 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--raw_scale\",                                                                  Python with 68.16 confidence\n",
      "        type=float,                                                                     Python with 96.24 confidence\n",
      "        default=255.0,                                                                  Python with 99.98 confidence\n",
      "        help=\"Multiply raw input by this scale before preprocessing.\"                   Python with 99.97 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--channel_swap\",                                                               Python with 96.71 confidence\n",
      "        default='2,1,0',                                                                Python with 100.00 confidence\n",
      "        help=\"Order to permute input channels. The default converts \" +                 Python with 100.00 confidence\n",
      "             \"RGB -> BGR since BGR is the Caffe default by way of OpenCV.\"              C++ with 74.63 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    parser.add_argument(                                                                Python with 99.96 confidence\n",
      "        \"--ext\",                                                                        Python with 77.83 confidence\n",
      "        default='jpg',                                                                  Python with 100.00 confidence\n",
      "        help=\"Image file extension to take as input when a directory \" +                Python with 99.84 confidence\n",
      "             \"is given as the input file.\"                                              Python with 99.98 confidence\n",
      "    )                                                                                   Python with 99.95 confidence\n",
      "    args = parser.parse_args()                                                          Python with 100.00 confidence\n",
      "\n",
      "    image_dims = [int(s) for s in args.images_dim.split(',')]                           Python with 100.00 confidence\n",
      "\n",
      "    mean, channel_swap = None, None                                                     Python with 99.99 confidence\n",
      "    if args.mean_file:                                                                  Python with 99.99 confidence\n",
      "        mean = np.load(args.mean_file)                                                  Python with 99.99 confidence\n",
      "    if args.channel_swap:                                                               Python with 100.00 confidence\n",
      "        channel_swap = [int(s) for s in args.channel_swap.split(',')]                   Python with 100.00 confidence\n",
      "\n",
      "    if args.gpu:                                                                        Python with 99.98 confidence\n",
      "        caffe.set_mode_gpu()                                                            C++ with 88.61 confidence\n",
      "        print(\"GPU mode\")                                                               Python with 99.89 confidence\n",
      "    else:                                                                               Python with 99.96 confidence\n",
      "        caffe.set_mode_cpu()                                                            C++ with 78.35 confidence\n",
      "        print(\"CPU mode\")                                                               Python with 99.38 confidence\n",
      "\n",
      "    # Make classifier.                                                                  Python with 100.00 confidence\n",
      "    classifier = caffe.Classifier(args.model_def, args.pretrained_model,                Python with 99.81 confidence\n",
      "            image_dims=image_dims, mean=mean,                                           Python with 98.75 confidence\n",
      "            input_scale=args.input_scale, raw_scale=args.raw_scale,                     Python with 99.63 confidence\n",
      "            channel_swap=channel_swap)                                                  Python with 99.74 confidence\n",
      "\n",
      "    # Load numpy array (.npy), directory glob (*.jpg), or image file.                   Python with 99.97 confidence\n",
      "    args.input_file = os.path.expanduser(args.input_file)                               Python with 100.00 confidence\n",
      "    if args.input_file.endswith('npy'):                                                 Python with 100.00 confidence\n",
      "        print(\"Loading file: %s\" % args.input_file)                                     Python with 99.98 confidence\n",
      "        inputs = np.load(args.input_file)                                               Python with 99.99 confidence\n",
      "    elif os.path.isdir(args.input_file):                                                Python with 100.00 confidence\n",
      "        print(\"Loading folder: %s\" % args.input_file)                                   Python with 99.98 confidence\n",
      "        inputs =[caffe.io.load_image(im_f)                                              Python with 96.75 confidence\n",
      "                 for im_f in glob.glob(args.input_file + '/*.' + args.ext)]             Python with 99.98 confidence\n",
      "    else:                                                                               Python with 99.96 confidence\n",
      "        print(\"Loading file: %s\" % args.input_file)                                     Python with 99.98 confidence\n",
      "        inputs = [caffe.io.load_image(args.input_file)]                                 Python with 99.96 confidence\n",
      "\n",
      "    print(\"Classifying %d inputs.\" % len(inputs))                                       Python with 99.99 confidence\n",
      "\n",
      "    # Classify.                                                                         Python with 100.00 confidence\n",
      "    start = time.time()                                                                 Python with 99.99 confidence\n",
      "    predictions = classifier.predict(inputs, not args.center_only)                      Python with 99.99 confidence\n",
      "    print(\"Done in %.2f s.\" % (time.time() - start))                                    Python with 100.00 confidence\n",
      "\n",
      "    # Save                                                                              Python with 100.00 confidence\n",
      "    print(\"Saving results into %s\" % args.output_file)                                  Python with 100.00 confidence\n",
      "    np.save(args.output_file, predictions)                                              Python with 99.99 confidence\n",
      "\n",
      "\n",
      "if __name__ == '__main__':                                                              Python with 100.00 confidence\n",
      "    main(sys.argv)                                                                      Python with 99.99 confidence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints lines in a file, along with the model's predicted language and confidence level.\n",
    "\n",
    "testCodePath = \"./data/test_code/pythonTest.py\"\n",
    "\n",
    "testCode = open(testCodePath).read()\n",
    "testLines = testCode.split(\"\\n\")\n",
    "maxLength = max([len(line) for line in testLines])\n",
    "for line in testLines:\n",
    "    if len(line) == 0:\n",
    "        print \"\"\n",
    "    else:\n",
    "        scores = queryModel(model, line, indexing)\n",
    "        bestLang, bestScore = scores[0]\n",
    "        print \"%-*s%s with %.02f confidence\" % (maxLength, line, bestLang, 100 * bestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
